{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sung_lec05_tip(1)_learning_rate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/THU-PM/blob/master/Copy_of_sung_lec05_tip(1)_learning_rate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvhV71WUTwb",
        "colab_type": "text"
      },
      "source": [
        "# Learning rate\n",
        "\n",
        "이번시간에는 Optimizer 함수의 매개변수로 주로 쓰이는 **learning_rate**에 대해 살펴보겠습니다. \n",
        "\n",
        "learning rate란 쉽게 말해 학습의 속도를 결정짓는 요소로 설명할 수 있습니다. 학습이 진행되는 동안 모델은 입력데이터에 대해 모델에서 생성한 예측값과 실제 값(타깃 값)의 차이인 손실함수 값을 바탕으로 가중치 update를 수행합니다. 이때 **가중치 update의 정도를 결정짓는 요소**가 learning_rate 입니다. \n",
        "\n",
        "learning rate가 학습의 속도와 관련있다고 해서 마냥 크거나 너무 작은 값을 사용해서는 안됩니다. 아래 예제를 통해서 확인해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcI1Gtr3edLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyssWYU-0-e",
        "colab_type": "text"
      },
      "source": [
        "학습에 사용할 데이터를 정의하겠습니다. 이번 예제는 3개의 속성을 갖는 입력데이터를 바탕으로 3개의 class중 하나로 분류하는 softmax 문제를 사용하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "305l6PT44xdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = np.array([[1, 2, 1],\n",
        "                   [1, 3, 2],\n",
        "                   [1, 3, 4],\n",
        "                   [1, 5, 5],\n",
        "                   [1, 7, 5],\n",
        "                   [1, 2, 5],\n",
        "                   [1, 6, 6],\n",
        "                   [1, 7, 7]], dtype=np.float32)\n",
        "y_data = np.array([[0, 0, 1],\n",
        "                   [0, 0, 1],\n",
        "                   [0, 0, 1],\n",
        "                   [0, 1, 0],\n",
        "                   [0, 1, 0],\n",
        "                   [0, 1, 0],\n",
        "                   [1, 0, 0],\n",
        "                   [1, 0, 0]], dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLCHhP8DfV2p",
        "colab_type": "text"
      },
      "source": [
        "Learning rate을 바꿔가면서 모델의 성능을 테스트해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD46NQJUc-ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try different learning_rate\n",
        "#learning_rate = 65535  # ? it works too hahaha\n",
        "#learning_rate = 1e-8  # small learning rate won't work either\n",
        "learning_rate = 0.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CyAkiUmdFqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=3, input_shape=(3,), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=learning_rate), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC2qFZOcdJhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(x_data, y_data, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRVhQ8STNZM",
        "colab_type": "text"
      },
      "source": [
        "학습 과정동안 손실함수의 변화값을 그려보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP1cTny5TWLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmo-F9YO_LrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKzzezsthr-x",
        "colab_type": "text"
      },
      "source": [
        "learning rate가 너무 크면, 초기 학습속도는 빠른듯 한데, 최적해를 찾지 못하고 손실함수 값이 이러저리 진동하는 것을 알 수 있습니다. \n",
        "\n",
        "learning rate가 너무 작으면 가중치의 update 속도가 느려 학습속도가 너무 늦습니다. 즉, 주어진 epochs 안에 최적해 근처에 도달하지 못할 수 있고, 예제에서 처럼 정확도는 제자리 걸음을 보일 수 있네요. \n",
        "\n",
        "적절한 learning rate를 찾는 공식 같은 것은 없습니다. 다양한 문제에 대해서 많은 연습을 통해서 여러분들은 자신만의 규칙을 찾을 수 있을 것입니다. 지금 얘기할 수 있는 부분은 learning_rate을 바꿔가며 다양하게 모델을 학습해 보는 것이 바람직하다 정도입니다. 향후에 조금더 나은 guideline 을 제시할 수 있습니다. "
      ]
    }
  ]
}